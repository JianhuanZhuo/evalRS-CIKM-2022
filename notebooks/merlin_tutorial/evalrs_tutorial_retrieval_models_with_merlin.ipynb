{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for the EvalRS competition\n",
    "# Retrieval models with Merlin\n",
    "\n",
    "In this notebook, we present a tutorial on how to use the open-source [NVIDIA Merlin](https://github.com/NVIDIA-Merlin/) framework to build and train a retrieval model for EvalRS competition. We are going to use the [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) library for preprocessing and [Merlin Models](https://github.com/NVIDIA-Merlin/models) for building and training Tensorflow-based retrieval models.\n",
    "\n",
    "### Retrieval models\n",
    "Retrieval models are recsys scalable models that are able to retrieve a large number of candidate items for recommendation. They are typically used in two-stage recsys pipelines, where the retrieval stage scores hundreds of thousands or millions of items and then the ranking stage scores the candidate items with more features or with a more powerful architecture.\n",
    "For ML-based candidate retrieval model, as it needs to quickly score millions of items for a given user, the retrieval models typically produce recommendation scores by just computing the dot product between user and item representations. Popular choices of such models are Matrix Factorization, which learns low-rank user and item embeddings, and the Two-Tower architecture, which is a neural network with two MLP towers where both user and item features are fed to generate user and item embeddings in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs EvalRS dependencies\n",
    "#!pip install -r ../../requirements.txt\n",
    "# Installs Merlin dependencies\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Basic imports, read the credentials from the env file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "# Imports EvalRS dependencies\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../upload.env')\n",
    "\n",
    "EMAIL = os.getenv('EMAIL')  # the e-mail you used to sign up\n",
    "assert EMAIL != '' and EMAIL is not None\n",
    "BUCKET_NAME = os.getenv('BUCKET_NAME') # you received it in your e-mail\n",
    "PARTICIPANT_ID = os.getenv('PARTICIPANT_ID') # you received it in your e-mail\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY') # you received it in your e-mail\n",
    "AWS_SECRET_KEY = os.getenv('AWS_SECRET_KEY') # you received it in your e-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Specify some other global variables to improve local iteration and debugging, for example setting a LIMIT to work with a smaller, faster test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: as long as there is a limit specified, the runner won't upload results: make sure to have LIMIT=0 when you want to submit to the leaderboard!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from evaluation.EvalRSRunner import EvalRSRunner\n",
    "from evaluation.EvalRSRunner import ChallengeDataset\n",
    "from reclist.abstractions import RecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFM dataset already downloaded. Skipping download.\n",
      "Loading dataset.\n",
      "Generating folds.\n",
      "Generating dataset hashes.\n"
     ]
    }
   ],
   "source": [
    "dataset = ChallengeDataset(force_download=False)  # note, if YES, the dataset will be donwloaded again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runner = EvalRSRunner(\n",
    "    dataset=dataset,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    participant_id=PARTICIPANT_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    email=EMAIL\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates a retrieval recsys pipeline with Merlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from merlin.dag import ColumnSelector\n",
    "from merlin.schema import Schema, Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 19:35:33.012637: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-04 19:35:34.004770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 19:35:34.949978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30488 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2022-08-04 19:35:34.951014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30973 MB memory:  -> device: 1, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import merlin.models.tf as mm\n",
    "from merlin.io import Dataset\n",
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.models.utils import schema_utils\n",
    "from merlin.models.tf.core.transformations import PopularityLogitsCorrection\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_frequencies(train_ds):   \n",
    "    \"\"\"Utility function that returns a TF tensor with the items (tracks) frequency\"\"\"\n",
    "    schema = train_ds.schema\n",
    "    # Gets the item ids cardinality\n",
    "    item_id_feature = schema.select_by_tag(Tags.ITEM_ID)\n",
    "    item_id_feature_name = item_id_feature.column_names[0]\n",
    "    cardinalities = schema_utils.categorical_cardinalities(schema)\n",
    "    item_id_cardinality = cardinalities[item_id_feature_name]\n",
    "\n",
    "    item_id_feature_name = schema.select_by_tag(Tags.ITEM_ID).column_names[0]\n",
    "\n",
    "    item_frequencies_df = (\n",
    "        train_ds.to_ddf()\n",
    "        .groupby(item_id_feature_name)\n",
    "        .size()\n",
    "        .to_frame(\"freq\")\n",
    "        .compute()\n",
    "    )\n",
    "    assert len(item_frequencies_df) <= item_id_cardinality\n",
    "    assert item_frequencies_df.index.max() < item_id_cardinality\n",
    "\n",
    "    # Completing the missing item ids and filling freq with 0\n",
    "    item_frequencies_df = item_frequencies_df.reindex(\n",
    "        np.arange(0, item_id_cardinality)\n",
    "    ).fillna(0)\n",
    "    assert len(item_frequencies_df) == item_id_cardinality\n",
    "\n",
    "    item_frequencies_df = item_frequencies_df.sort_index()\n",
    "    item_frequencies_df[\"dummy\"] = 1\n",
    "    item_frequencies_df[\"expected_id\"] = item_frequencies_df[\"dummy\"].cumsum() - 1\n",
    "    assert (\n",
    "        item_frequencies_df.index == item_frequencies_df[\"expected_id\"]\n",
    "    ).all(), f\"The item id feature ({item_id_feature_name}) should be contiguous from 0 to {item_id_cardinality-1}\"\n",
    "\n",
    "    item_frequencies = tf.convert_to_tensor(\n",
    "        item_frequencies_df[\"freq\"].values\n",
    "    )\n",
    "\n",
    "    return item_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our model for EvalRS by inheriting from the RecModel, which must implement the `train()` and the `predict()` methods. Within `train()` we need to define our full pipeline for preprocessing and training data. \n",
    "\n",
    "#### NVTabular\n",
    "For preprocessing, we use the [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) library, which provides very handful features for common operations like (label) encoding categorical features for embeddings and for normalizing continuous features.\n",
    "NVTabular works with CPUs, uses GPUs and NVIDIA RAPIDS when available for GPU-accelerated preprocessing. For this example we are installing NVTabular using `pip` for CPU usage, but if you want to speedup preprocessing with GPUs you can install NVTabular using `conda` as explained in its [repo](https://github.com/NVIDIA-Merlin/NVTabular).\n",
    "\n",
    "#### Merlin Models\n",
    "For model definition and training we use [Merlin Models](https://github.com/NVIDIA-Merlin/models). It provides a Tensorflow (Keras) API where you can easily build state-of-the-art retrieval and ranking models. One of the core ideas of Models is to leverage the schema generated during preprocessing by **NVTabular** to create automatically the necessary embedding tables for categorical features and define the target of the model.\n",
    "Here we will be implementing two retrieval models: `MatrixFactorizationModel` and `TwoTowerModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRetrievalModel(RecModel):\n",
    "    \n",
    "    def __init__(self, items_df: pd.DataFrame, users_df: pd.DataFrame, top_k: int=20, \n",
    "                 train_dataset_cache=None, user_ids_cache=None, predict_batch_size=1024, **kwargs):\n",
    "        super(RecModel, self).__init__()\n",
    "        self.items_df = items_df\n",
    "        self.users_df = users_df\n",
    "        self.top_k = top_k\n",
    "        self.train_dataset_cache = train_dataset_cache\n",
    "        self.user_ids_cache = user_ids_cache\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.hparams = kwargs\n",
    "    \n",
    "    def get_nvtabular_preproc_workflow(self):\n",
    "        \"\"\"Defines an NVTabular preprocessing workflow\"\"\"\n",
    "        \n",
    "        user_id_col = [\"user_id\"] \n",
    "        user_cat_cols = [\"country\", \"gender\"]\n",
    "        user_age_col = [\"age\"]\n",
    "\n",
    "        user_continuous_cols = [\n",
    "            'novelty_artist_avg_month', 'novelty_artist_avg_6months', 'novelty_artist_avg_year',\n",
    "            'mainstreaminess_avg_month', 'mainstreaminess_avg_6months', 'mainstreaminess_avg_year', 'mainstreaminess_global',\n",
    "            'relative_le_per_weekday1', 'relative_le_per_weekday2', 'relative_le_per_weekday3',\n",
    "             'relative_le_per_weekday4', 'relative_le_per_weekday5','relative_le_per_weekday6', 'relative_le_per_weekday7',\n",
    "             'relative_le_per_hour0', 'relative_le_per_hour1','relative_le_per_hour2', 'relative_le_per_hour3',\n",
    "             'relative_le_per_hour4', 'relative_le_per_hour5', 'relative_le_per_hour6', 'relative_le_per_hour7', \n",
    "             'relative_le_per_hour8', 'relative_le_per_hour9', 'relative_le_per_hour10', 'relative_le_per_hour11',\n",
    "             'relative_le_per_hour12', 'relative_le_per_hour13', 'relative_le_per_hour14', 'relative_le_per_hour15',\n",
    "             'relative_le_per_hour16', 'relative_le_per_hour17','relative_le_per_hour18', 'relative_le_per_hour19',\n",
    "             'relative_le_per_hour20', 'relative_le_per_hour21', 'relative_le_per_hour22', 'relative_le_per_hour23', \n",
    "        ]\n",
    "\n",
    "        user_counts_cols = ['playcount', 'cnt_listeningevents', 'cnt_distinct_tracks', \n",
    "                                'cnt_distinct_artists', 'cnt_listeningevents_per_week']\n",
    "\n",
    "        item_id = [\"track_id\"]\n",
    "        item_features_cols = [\"artist_id\", \"album_id\"] \n",
    "\n",
    "\n",
    "        user_id = user_id_col >> ops.Categorify() >> ops.TagAsUserID()\n",
    "        user_feat_cat = user_cat_cols >> ops.Categorify() >> ops.TagAsUserFeatures()\n",
    "        age_boundaries = list(np.arange(0,100,5))\n",
    "        user_age = user_age_col >> ops.FillMissing(0) >> ops.Bucketize(age_boundaries) >> ops.Categorify() >> ops.TagAsUserFeatures()\n",
    "        user_feat_cont = user_continuous_cols >> ops.FillMedian() >> ops.Normalize() >> ops.TagAsUserFeatures()\n",
    "        user_feat_count = user_counts_cols >> ops.Clip(min_value=1) >> ops.FillMedian() >> ops.LogOp() >> ops.Normalize() >> ops.TagAsUserFeatures()\n",
    "        user_features = user_id + user_feat_cat + user_age + user_feat_cont + user_feat_count\n",
    "\n",
    "        item_id = item_id >> ops.Categorify() >> ops.TagAsItemID()\n",
    "        item_cat_feat = item_features_cols >> ops.Categorify() >> ops.TagAsItemFeatures()\n",
    "        item_features = item_id + item_cat_feat\n",
    "\n",
    "        outputs = user_features + item_features\n",
    "        workflow = nvt.Workflow(outputs)\n",
    "        return workflow\n",
    "    \n",
    "    def preprocess_dataset(self, events_df):\n",
    "        \"\"\"Preprocess the dataset using an NVTabular workflow\"\"\"        \n",
    "        nvt_dataset = nvt.Dataset(events_df)\n",
    "        \n",
    "        nvt_workflow = self.get_nvtabular_preproc_workflow()\n",
    "        nvt_workflow.fit(nvt_dataset)\n",
    "        schema = nvt_workflow.output_schema\n",
    "        \n",
    "        # Saving the NVT workflow to disk, to be able to retrieve the mapping of categ features\n",
    "        NVT_WORKFLOW_PATH = 'nvt_workflow_outputs/'\n",
    "        shutil.rmtree(NVT_WORKFLOW_PATH, ignore_errors=True)\n",
    "        nvt_workflow.save(NVT_WORKFLOW_PATH)\n",
    "        # Loads mapping of categ features\n",
    "        self.user_ids_mapping_df = pd.read_parquet(NVT_WORKFLOW_PATH+\n",
    "                                                   'categories/unique.user_id.parquet')[['user_id']]\n",
    "        self.track_ids_mapping_df = pd.read_parquet(NVT_WORKFLOW_PATH+\n",
    "                                                    'categories/unique.track_id.parquet')[['track_id']]\n",
    "        \n",
    "        transformed_dataset = nvt_workflow.transform(nvt_dataset)        \n",
    "        transformed_df = transformed_dataset.persist().repartition(npartitions=10)  \n",
    "        \n",
    "        return transformed_df, schema\n",
    "    \n",
    "        \n",
    "    def get_item_retrieval_task(self):        \n",
    "        \"\"\"Defines the item retrieval task to be used by the retrieval models\"\"\"\n",
    "        items_frequencies = get_item_frequencies(self.train_dataset)\n",
    "        \n",
    "        post_logits = None\n",
    "        reg_factor = self.hparams['logq_correction_factor']\n",
    "        if reg_factor > 0.0:\n",
    "            post_logits = PopularityLogitsCorrection(\n",
    "                items_frequencies, reg_factor=reg_factor, schema=self.schema\n",
    "            )\n",
    "        \n",
    "        item_retrieval_task = mm.ItemRetrievalTask(self.schema, \n",
    "                                        logits_temperature=self.hparams['logits_temperature'],\n",
    "                                         post_logits=post_logits)\n",
    "        \n",
    "        return item_retrieval_task\n",
    "\n",
    "    \n",
    "    def get_model(self):\n",
    "        \"\"\"Defines the model architecture. Needs to be overridden by the child class\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def compile_model(self, model):\n",
    "        \"\"\"Compiles the Keras model setting the metrics, loss, learning rate and optimizer\"\"\"\n",
    "        metrics = [mm.TopKMetricsAggregator(mm.RecallAt(20), mm.MRRAt(20))]\n",
    "        \n",
    "        lerning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            self.hparams['lr'],\n",
    "            decay_steps=self.hparams['lr_decay_steps'],\n",
    "            decay_rate=self.hparams['lr_decay_rate'],\n",
    "            staircase=True,\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lerning_rate)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, label_smoothing=self.hparams['label_smoothing'],\n",
    "        )\n",
    "        \n",
    "        model.compile(optimizer, loss=loss, metrics=metrics, run_eagerly=False)\n",
    "        \n",
    "    def get_items_topk_recommender_model(\n",
    "        self,\n",
    "        train_dataset: Dataset, \n",
    "        schema, \n",
    "        model, \n",
    "        ):        \n",
    "        \"\"\"Converts a retrieval model into a Top-k recommender model, which\n",
    "        takes only user features as input, generates the user representations \n",
    "        (e.g. by taking the user embedding for MF or using the user tower to generate it)\n",
    "        and uses scores all cached item representations to return the most similar items \n",
    "        (P.s. This procedure would be done by an ANN engine in production)\"\"\"\n",
    "        item_features = schema.select_by_tag(Tags.ITEM).column_names\n",
    "        item_dataset = train_dataset.to_ddf()[item_features].drop_duplicates(subset=['track_id'], keep='last').compute()\n",
    "        item_dataset = Dataset(item_dataset)\n",
    "\n",
    "        return model.to_top_k_recommender(item_dataset, k=self.top_k)\n",
    "        \n",
    "    def train_model(self, model, train_dataset):\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            epochs=self.hparams['epochs'],\n",
    "            batch_size=self.hparams['train_batch_size'],\n",
    "            #steps_per_epoch=5,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            train_metrics_steps=100,\n",
    "        )\n",
    "        \n",
    "\n",
    "    def train(self, train_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Implement here your training logic. Since our example method is a simple random model,\n",
    "        we actually don't use any training data to build the model, but you should ;-)\n",
    "        At the end of training, make sure the class contains a trained model you can use in the predict method.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.train_dataset_cache is not None:\n",
    "            train_dataset = self.train_dataset_cache\n",
    "            schema = self.train_dataset_cache.schema\n",
    "        else:\n",
    "            \n",
    "            print(\"Merging events and user features\")\n",
    "            events_df = train_df.merge(self.users_df, on='user_id', how='inner')\n",
    "\n",
    "            print(\"Start preprocessing\")\n",
    "            transformed_df, schema = self.preprocess_dataset(events_df)\n",
    "            train_dataset = Dataset(transformed_df, schema=schema)\n",
    "            \n",
    "            self.train_dataset_cache = train_dataset\n",
    "            \n",
    "        self.train_dataset = train_dataset\n",
    "        self.schema = self.train_dataset.schema\n",
    "        \n",
    "        print(\"Building the model\")\n",
    "        model = self.get_model()\n",
    "        self.compile_model(model)                \n",
    "        \n",
    "        print(\"Start training\")\n",
    "        self.train_model(model, train_dataset)        \n",
    "        self.trained_model = model\n",
    "        \n",
    "        print(\"Preparing retrieval model for prediction\")\n",
    "        self.topk_rec_model = self.get_items_topk_recommender_model(train_dataset, schema, model)\n",
    "        \n",
    "        print(\"Caching users transformed features\")\n",
    "        self.users_schema = schema.select_by_tag(Tags.USER)\n",
    "        user_features = self.users_schema.column_names\n",
    "        self.users_transformed_df = train_dataset.to_ddf()[user_features].drop_duplicates(subset=['user_id'], keep='last').compute()\n",
    "        # Adding the raw (original) user id to the dataframe\n",
    "        self.users_transformed_df = self.users_transformed_df.merge(self.user_ids_mapping_df.rename({'user_id': 'raw_user_id'}, axis=1),\n",
    "                                                                    left_on='user_id', right_index=True)\n",
    "\n",
    "        print(\"Training completed!\")         \n",
    "\n",
    "    def predict(self, user_ids: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"        \n",
    "        This function takes as input all the users that we want to predict the top-k items for, and \n",
    "        returns all the predicted songs.\n",
    "\n",
    "        While in this example is just a random generator, the same logic in your implementation \n",
    "        would allow for batch predictions of all the target data points.        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.user_ids_cache is not None:\n",
    "            user_ids = self.user_ids_cache\n",
    "        else:\n",
    "            self.user_ids_cache = user_ids\n",
    "            \n",
    "        self.predict_user_ids = user_ids\n",
    "        \n",
    "        print(\"Start prediction\")\n",
    "        print(\"# users:\",len(user_ids))\n",
    "        test_users_df = user_ids.rename({'user_id': 'raw_user_id'}, axis=1).merge(self.users_transformed_df, \n",
    "                                                       on='raw_user_id', how='left')\n",
    "        self.test_users_df = test_users_df\n",
    "        test_users_found_df = test_users_df[~test_users_df[test_users_df.columns[1]].isna()]\n",
    "        test_users_not_found_df = test_users_df[test_users_df[test_users_df.columns[1]].isna()]        \n",
    "\n",
    "        test_users_dataset = Dataset(test_users_found_df, self.users_schema)\n",
    "        test_batched_dataset = BatchedDataset(\n",
    "            test_users_dataset, batch_size=self.predict_batch_size, shuffle=False, schema=self.users_schema\n",
    "        )        \n",
    "        \n",
    "        print(f\"Predicting Top-{self.top_k} items for test users\")\n",
    "        predictions = self.topk_rec_model.predict(test_batched_dataset)[1].astype(np.int32) \n",
    "        \n",
    "        print(f\"Converting user ids and predicted item ids to the original ids\")\n",
    "        predictions_converted = self.convert_prediction_item_ids(predictions)\n",
    "        \n",
    "        user_ids_found_converted = test_users_found_df['raw_user_id'].values.astype(np.int32)        \n",
    "        user_ids_not_found_converted = test_users_not_found_df['raw_user_id'].values.astype(np.int32)\n",
    "        \n",
    "        # Merging raw user id with top-k predictions\n",
    "        user_predictions_found_converted = np.concatenate((np.expand_dims(user_ids_found_converted, -1), predictions_converted), axis=1)\n",
    "        user_predictions_not_found_converted = np.concatenate((np.expand_dims(user_ids_not_found_converted, -1), \n",
    "                                                               np.zeros((user_ids_not_found_converted.shape[0], predictions_converted.shape[1]))), axis=1)\n",
    "        # Combining predictions of users found and not found\n",
    "        user_predictions_converted = np.vstack([user_predictions_found_converted, user_predictions_not_found_converted])        \n",
    "        user_predictions_df = pd.DataFrame(user_predictions_converted, columns=['user_id', *[str(i) for i in range(predictions_converted.shape[1])]]).set_index('user_id')\n",
    "        # Ensures predictions output dataframe is sorted the same as input user_ids order\n",
    "        user_predictions_df = user_predictions_df.loc[user_ids['user_id'].values]\n",
    "        self.user_predictions_df = user_predictions_df\n",
    "        print(\"Finish prediction\")\n",
    "        return user_predictions_df\n",
    "    \n",
    "    def convert_user_ids(self, user_ids):\n",
    "        \"\"\"Converts the encoded user ids into the original ids\"\"\"\n",
    "        raw_user_ids = self.user_ids_mapping_df['user_id'].loc[user_ids].values\n",
    "        return raw_user_ids\n",
    "    \n",
    "    def convert_prediction_item_ids(self,predictions):\n",
    "        \"\"\"Converts the encoded predicted item ids into the original item ids\"\"\"\n",
    "        raw_topk_predicted_item_ids = self.track_ids_mapping_df['track_id'].loc[predictions.reshape(-1)].values\n",
    "        raw_topk_predicted_item_ids = np.reshape(raw_topk_predicted_item_ids, (-1, predictions.shape[1]))\n",
    "        return raw_topk_predicted_item_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMFModel(MyRetrievalModel):\n",
    "    \n",
    "    def get_model(self):      \n",
    "        item_retrieval_task = self.get_item_retrieval_task()\n",
    "\n",
    "        model = mm.MatrixFactorizationModel(\n",
    "            self.schema,\n",
    "            dim=self.hparams['mf_dim'],\n",
    "            prediction_tasks=item_retrieval_task,\n",
    "            embeddings_l2_reg=self.hparams['embeddings_l2_reg']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model = MyMFModel(\n",
    "    items_df=dataset.df_tracks,\n",
    "    users_df=dataset.df_users,\n",
    "    train_dataset_cache=train_dataset_cache2, \n",
    "    user_ids_cache=user_ids_cache2,\n",
    "    \n",
    "    # Training hparams\n",
    "    epochs=5,\n",
    "    train_batch_size=8192,\n",
    "    lr=1e-3,\n",
    "    lr_decay_steps=100,\n",
    "    lr_decay_rate=0.96,\n",
    "    label_smoothing=0.0,\n",
    "    \n",
    "    # Model hparams\n",
    "    logq_correction_factor=1.0,\n",
    "    embeddings_l2_reg=5e-6,\n",
    "    logits_temperature=1.8,\n",
    "    mf_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_ids_cache2 = my_model.user_ids_cache\n",
    "#train_dataset_cache2 = my_model.train_dataset_cache\n",
    "#my_model.trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model.user_ids_mapping_df = pd.read_parquet('nvt_workflow_outputs/' \n",
    "                                           'categories/unique.user_id.parquet')[['user_id']]\n",
    "mf_model.track_ids_mapping_df = pd.read_parquet('nvt_workflow_outputs/' \n",
    "                                            'categories/unique.track_id.parquet')[['track_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Finally, we run the evaluation code: remember, if LIMIT is not 0, your submission won't be uploaded but the loop may still be useful for you to debug / iterate locally_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin Evaluation... \n",
      "\n",
      "Performing Training for fold 1/4...\n",
      "Building the model\n",
      "Start training\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:merlin_models:The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/838 [========>.....................] - ETA: 35s - loss: 9.1677 - recall_at_20: 0.0023 - mrr_at_20: 5.1180e-04 - regularization_loss: 0.0149"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/projects/competitions/evalRS-CIKM-2022/evaluation/EvalRSRunner.py:259\u001b[0m, in \u001b[0;36mEvalRSRunner.evaluate\u001b[0;34m(self, model, seed, upload, limit, custom_RecList, debug, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPerforming Training for fold \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fold \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_folds))\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerforming Evaluation for fold \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fold \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_folds))\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mMyRetrievalModel.train\u001b[0;34m(self, train_df)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_model(model)                \n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing retrieval model for prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mMyRetrievalModel.train_model\u001b[0;34m(self, model, train_dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, train_dataset):\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_batch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch=5,\u001b[39;49;00m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_metrics_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/merlin/models/tf/models/base.py:536\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, train_metrics_steps, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_metrics_callback(callbacks, train_metrics_steps)\n\u001b[1;32m    530\u001b[0m fit_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    531\u001b[0m     k: v\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_metrics_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__class__\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    534\u001b[0m }\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:1092\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03m\"\"\"Updates the progbar.\"\"\"\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_init_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps:\n\u001b[1;32m   1094\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/callbacks.py:1069\u001b[0m, in \u001b[0;36mProgbarLogger._maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[1;32m   1065\u001b[0m   \u001b[38;5;66;03m# Update the existing stateful metrics as `self.model.metrics` may contain\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m   \u001b[38;5;66;03m# updated metrics after `MetricsContainer` is built in the first train\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m   \u001b[38;5;66;03m# step.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics\u001b[38;5;241m.\u001b[39munion(\n\u001b[0;32m-> 1069\u001b[0m       \u001b[38;5;28mset\u001b[39m(m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m))\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1072\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;241m=\u001b[39m Progbar(\n\u001b[1;32m   1073\u001b[0m       target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[1;32m   1074\u001b[0m       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1075\u001b[0m       stateful_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics,\n\u001b[1;32m   1076\u001b[0m       unit_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/engine/training.py:741\u001b[0m, in \u001b[0;36mModel.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[1;32m    738\u001b[0m   \u001b[38;5;66;03m# TODO(omalleyt): Track `LossesContainer` and `MetricsContainer` objects\u001b[39;00m\n\u001b[1;32m    739\u001b[0m   \u001b[38;5;66;03m# so that attr names are not load-bearing.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 741\u001b[0m     metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\n\u001b[1;32m    742\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/keras/engine/compile_utils.py:122\u001b[0m, in \u001b[0;36mLossesContainer.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built:\n\u001b[1;32m    120\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m    121\u001b[0m per_output_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 122\u001b[0m     metric_obj \u001b[38;5;28;01mfor\u001b[39;00m metric_obj \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_per_output_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metric_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m ]\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_metric] \u001b[38;5;241m+\u001b[39m per_output_metrics\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/tensorflow/python/util/nest.py:453\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    452\u001b[0m expand_composites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "runner.evaluate(model=mf_model, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-tower architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Two-Tower Model consists of item (candidate) and user (query) encoder towers. With two towers, the model can learn representations (embeddings) for queries and candidates separately.\n",
    "\n",
    "<img src=\"./images/TwoTower.png\"  width=\"30%\">\n",
    "\n",
    "Image Adapted from: [Off-policy Learning in Two-stage Recommender Systems](https://dl.acm.org/doi/abs/10.1145/3366423.3380130)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTwoTowerModel(MyRetrievalModel):\n",
    "    \n",
    "    def get_model(self):   \n",
    "        item_retrieval_task = self.get_item_retrieval_task()\n",
    "        \n",
    "        model = mm.TwoTowerModel(\n",
    "            self.schema,\n",
    "            query_tower=mm.MLPBlock(\n",
    "                self.hparams['tt_mlp_layers'],\n",
    "                activation=self.hparams['tt_mlp_activation'],\n",
    "                no_activation_last_layer=True,    \n",
    "                dropout=self.hparams['tt_mlp_dropout'],                \n",
    "                kernel_regularizer=regularizers.l2(self.hparams['tt_mlp_l2_reg']),\n",
    "                bias_regularizer=regularizers.l2(self.hparams['tt_mlp_l2_reg']),\n",
    "            ),\n",
    "            embedding_options=mm.EmbeddingOptions(\n",
    "                infer_embedding_sizes=True,\n",
    "                infer_embedding_sizes_multiplier=self.hparams['tt_infer_embedding_sizes_multiplier'],\n",
    "                embeddings_l2_reg=self.hparams['embeddings_l2_reg'],\n",
    "            ),\n",
    "            prediction_tasks=item_retrieval_task\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_model = MyTwoTowerModel(\n",
    "    items_df=dataset.df_tracks,\n",
    "    users_df=dataset.df_users,\n",
    "    train_dataset_cache=train_dataset_cache2, \n",
    "    user_ids_cache=user_ids_cache2,\n",
    "    \n",
    "    # Training hparams\n",
    "    epochs=5,\n",
    "    train_batch_size=8192,\n",
    "    lr=1e-3,\n",
    "    lr_decay_steps=100,\n",
    "    lr_decay_rate=0.96,\n",
    "    label_smoothing=0.0,\n",
    "    \n",
    "    # Model hparams\n",
    "    logq_correction_factor=1.0,\n",
    "    embeddings_l2_reg=1e-5,\n",
    "    logits_temperature=1.8,\n",
    "    tt_mlp_layers=[128,64],\n",
    "    tt_mlp_activation=\"relu\",\n",
    "    tt_mlp_dropout=0.3,\n",
    "    tt_mlp_l2_reg=5e-5,\n",
    "    tt_infer_embedding_sizes_multiplier=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_cache2 = tt_model.user_ids_cache\n",
    "train_dataset_cache2 = tt_model.train_dataset_cache\n",
    "#tt_model.trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_model.user_ids_mapping_df = pd.read_parquet('nvt_workflow_outputs/' \n",
    "                                           'categories/unique.user_id.parquet')[['user_id']]\n",
    "tt_model.track_ids_mapping_df = pd.read_parquet('nvt_workflow_outputs/' \n",
    "                                            'categories/unique.track_id.parquet')[['track_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Finally, we run the evaluation code: remember, if LIMIT is not 0, your submission won't be uploaded but the loop may still be useful for you to debug / iterate locally_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin Evaluation... \n",
      "\n",
      "Performing Training for fold 1/4...\n",
      "Building the model\n",
      "Start training\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:merlin_models:The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838/838 [==============================] - 60s 67ms/step - loss: 8.4494 - recall_at_20: 0.0149 - mrr_at_20: 0.0030 - regularization_loss: 0.0549\n",
      "Epoch 2/5\n",
      "838/838 [==============================] - 57s 67ms/step - loss: 7.9282 - recall_at_20: 0.0421 - mrr_at_20: 0.0100 - regularization_loss: 0.0676\n",
      "Epoch 3/5\n",
      "838/838 [==============================] - 57s 67ms/step - loss: 7.6815 - recall_at_20: 0.0729 - mrr_at_20: 0.0182 - regularization_loss: 0.0715\n",
      "Epoch 4/5\n",
      "838/838 [==============================] - 57s 68ms/step - loss: 7.5499 - recall_at_20: 0.0978 - mrr_at_20: 0.0256 - regularization_loss: 0.0734\n",
      "Epoch 5/5\n",
      "838/838 [==============================] - 57s 67ms/step - loss: 7.4836 - recall_at_20: 0.1101 - mrr_at_20: 0.0310 - regularization_loss: 0.0741\n",
      "Preparing retrieval model for prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "WARNING:absl:Found untraced functions such as model_context_7_layer_call_fn, model_context_7_layer_call_and_return_conditional_losses, parallel_block_6_layer_call_fn, parallel_block_6_layer_call_and_return_conditional_losses, sequential_block_75_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj25sz0tc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj25sz0tc/assets\n",
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching users transformed features\n",
      "Training completed!\n",
      "Performing Evaluation for fold 1/4...\n",
      "Start prediction\n",
      "# users: 29731\n",
      "Predicting Top-20 items for test users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/projects/nvidia/nvidia_merlin/core/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 20ms/step\n",
      "Converting user ids and predicted item ids to the original ids\n",
      "Finish prediction\n",
      "WARNING: Dense representation not loaded \n",
      " Reason : [Errno 2] No such file or directory: './song2vec.wv'\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : stats\n",
      "Test Description : \n",
      "Test Result      : {'num_users': 29731, 'max_items': 1, 'min_items': 1}\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : HIT_RATE\n",
      "Test Description : \n",
      "Test Result      : 0.008879620598028994\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : MRR\n",
      "Test Description : \n",
      "Test Result      : 0.001742524267425828\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : MRR_COUNTRY\n",
      "Test Description : \n",
      "Test Result      : {\"AD\":0.0,\"AE\":0.0416666667,\"AF\":0.0,\"AL\":0.0,\"AM\":0.0,\"AQ\":0.0,\"AR\":0.0032258065,\"AT\":0.0029850746,\"AU\":0.0,\"AZ\":0.0,\"BA\":0.0,\"BB\":0.0,\"BD\":0.0,\"BE\":0.0,\"BG\":0.0,\"BI\":0.0,\"BM\":0.0,\"BO\":0.0,\"BR\":0.0015025505,\"BT\":0.0,\"BY\":0.0037878788,\"CA\":0.0016317016,\"CC\":0.0,\"CD\":0.0,\"CH\":0.0,\"CL\":0.0025252525,\"CN\":0.0,\"CO\":0.0,\"CR\":0.0,\"CU\":0.0,\"CX\":0.0,\"CY\":0.0,\"CZ\":0.0,\"DE\":0.0010153269,\"DK\":0.0007112376,\"DO\":0.0,\"EC\":0.0,\"EE\":0.0,\"EG\":0.0,\"EH\":0.0,\"ES\":0.0,\"ET\":0.0,\"FI\":0.0006641086,\"FJ\":0.0,\"FM\":0.0,\"FR\":0.0011363636,\"GE\":0.0,\"GR\":0.0,\"GS\":0.0,\"GT\":0.0,\"HK\":0.0,\"HN\":0.0,\"HR\":0.0,\"HT\":0.0,\"HU\":0.003968254,\"ID\":0.0007331378,\"IE\":0.0,\"IL\":0.0,\"IN\":0.0023148148,\"IR\":0.0064516129,\"IS\":0.0,\"IT\":0.0005,\"JM\":0.0,\"JO\":0.0,\"JP\":0.0017637231,\"KE\":0.0,\"KG\":0.0,\"KH\":0.0,\"KI\":0.0,\"KM\":0.0,\"KN\":0.0,\"KP\":0.0,\"KR\":0.0,\"KY\":0.0,\"KZ\":0.0,\"LA\":0.0,\"LB\":0.0,\"LI\":0.0,\"LK\":0.0,\"LR\":0.0,\"LT\":0.0087719298,\"LU\":0.0,\"LV\":0.0,\"MA\":0.0,\"MD\":0.0,\"ME\":0.0,\"MG\":0.0,\"MK\":0.0,\"MN\":0.0,\"MO\":0.0,\"MQ\":0.0,\"MT\":0.0,\"MU\":0.0,\"MV\":0.0,\"MX\":0.0,\"MY\":0.0,\"NC\":0.0,\"NE\":0.0,\"NG\":0.0,\"NI\":0.0,\"NL\":0.0027896538,\"NO\":0.0031751248,\"NP\":0.0,\"NU\":0.0,\"NZ\":0.0,\"OM\":0.0,\"PA\":0.0,\"PE\":0.0,\"PF\":0.0,\"PG\":0.0,\"PH\":0.0,\"PK\":0.0,\"PL\":0.000759152,\"PR\":0.0,\"PS\":0.0,\"PT\":0.0018083183,\"PY\":0.0,\"RO\":0.0,\"RS\":0.0,\"RU\":0.0008603761,\"SA\":0.0,\"SC\":0.0,\"SE\":0.0007046432,\"SG\":0.0,\"SH\":0.0,\"SI\":0.0,\"SK\":0.0,\"SO\":0.0,\"ST\":0.0,\"SV\":0.0,\"SY\":0.0,\"SZ\":0.0,\"TF\":0.0,\"TH\":0.0,\"TN\":0.0,\"TR\":0.0,\"TT\":0.0,\"TV\":0.0,\"TW\":0.0,\"TZ\":0.0,\"UA\":0.0012077295,\"UG\":0.0,\"UK\":0.0007984712,\"UM\":0.0,\"US\":0.0016762862,\"UY\":0.0,\"UZ\":0.0,\"VA\":0.0,\"VE\":0.0,\"VI\":0.0,\"VN\":0.0,\"WS\":0.0,\"ZA\":0.0,\"ZW\":0.0}\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : MRR_USER_ACTIVITY\n",
      "Test Description : \n",
      "Test Result      : {\"10\":0.0033295762,\"100\":0.0015566636,\"1000\":0.0019433737,\"10000\":0.0012987013}\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : MRR_ARTIST_POPULARITY\n",
      "Test Description : \n",
      "Test Result      : {\"10\":0.0022781344,\"100\":0.001730202,\"1000\":0.00166092,\"10000\":0.0017998401,\"100000\":0.0006535948}\n",
      "\n",
      "============= TEST RESULTS ===============\n",
      "Test Type        : MRR_GENDER\n",
      "Test Description : \n",
      "Test Result      : {\"f\":0.0020163836,\"m\":0.001051597,\"n\":0.0021048923}\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/projects/competitions/evalRS-CIKM-2022/evaluation/EvalRSRunner.py:262\u001b[0m, in \u001b[0;36mEvalRSRunner.evaluate\u001b[0;34m(self, model, seed, upload, limit, custom_RecList, debug, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerforming Evaluation for fold \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fold \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_folds))\n\u001b[0;32m--> 262\u001b[0m     results_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_RecList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_RecList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     fold_results_path\u001b[38;5;241m.\u001b[39mappend(results_path)\n\u001b[1;32m    266\u001b[0m raw_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/projects/competitions/evalRS-CIKM-2022/evaluation/EvalRSRunner.py:217\u001b[0m, in \u001b[0;36mEvalRSRunner._test_model\u001b[0;34m(self, model, fold, limit, custom_RecList)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# TODO: there might be some path issues\u001b[39;00m\n\u001b[1;32m    216\u001b[0m rlist\u001b[38;5;241m.\u001b[39mload_dense_repr(path_to_word_vectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./song2vec.wv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m report_path \u001b[38;5;241m=\u001b[39m \u001b[43mrlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m report_path\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/reclist/abstractions.py:187\u001b[0m, in \u001b[0;36mRecList.__call__\u001b[0;34m(self, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# iterate through tests\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_func_name, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rec_tests\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 187\u001b[0m     test_result \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# we could store the results in the test function itself\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# test.__func__.test_result = test_result\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_name\u001b[39m\u001b[38;5;124m'\u001b[39m: test\u001b[38;5;241m.\u001b[39mtest_type,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m: test\u001b[38;5;241m.\u001b[39mtest_desc,\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_result\u001b[39m\u001b[38;5;124m'\u001b[39m: test_result}\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenv/evalrs/lib/python3.8/site-packages/reclist/abstractions.py:97\u001b[0m, in \u001b[0;36mrec_test.<locals>.decorator.<locals>.w\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mw\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/competitions/evalRS-CIKM-2022/evaluation/EvalRSRecList.py:121\u001b[0m, in \u001b[0;36mEvalRSRecList.being_less_wrong\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m hits \u001b[38;5;241m=\u001b[39m hits_at_k(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_test, k\u001b[38;5;241m=\u001b[39mTOP_K_CHALLENGE)\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    120\u001b[0m misses \u001b[38;5;241m=\u001b[39m (hits \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 121\u001b[0m miss_gt_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_repr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmisses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrack_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# we calculate the score w.r.t to the first prediction\u001b[39;00m\n\u001b[1;32m    123\u001b[0m miss_pred_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_repr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_preds\u001b[38;5;241m.\u001b[39mloc[misses, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "runner.evaluate(model=tt_model, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you have learned how build retrieval models (MF, Two-Tower) with the [Merlin](https://github.com/NVIDIA-Merlin/) open-source framework for the EvalRS competition. \n",
    "Feel free to improve these models using Tensorflow/Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
